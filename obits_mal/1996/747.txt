
        Dr. Amos Tversky, a cognitive psychologist who changed the way experts in many fields think about how people make decisions about risks, benefits and probabilities, died on Sunday at his home in Stanford, Calif. He was 59.
        The cause was metastatic melanoma, said Stanford University, where he was the Davis-Brack Professor of Behavioral Sciences.
        Dr. Tversky (pronounced TUH-VER-skee) once said he merely examined in a scientific way things about behavior that were already known to "advertisers and used-car salesmen," and much of his work has indeed had an economic slant, shaping the way economists look at decision-making by consumers and business executives. It also influenced statisticians and other researchers interested in how decisions involving risk are made in fields like medicine or public policy.
        His research showed that people do not always behave rationally when they make decisions, that they generally put more emphasis on risk than benefits and  that there are many more quirks in the human reasoning process than many earlier economic and psychological theories had contended.
        Dr. Tversky began his work with decision-making in Israel with Dr. Daniel Kahneman, now of Princeton University. When they were instructors at Hebrew University in 1968, Dr. Kahneman said, they became fascinated by how fighter-pilot trainers, taking classes at the university, decided whether to use rewards or punishments to motivate their pilot trainees.
        Even though the trainers were told that rewards were more effective, they argued against that idea. The trainers said that when a student was praised for  a good flight, he was more likely to do less well the next time. When a student  was berated for a poor flight, he tended to do better the next time. Drs. Tversky and Kahneman recognized that the trainers were being misled because they did not recognize that the law of averages would predict that an unusual performance, good or bad, would be likely to be followed by a performance closer to average.
        That led them to experiments in the early 1970's showing that people could depend on things other than logic to make decisions, said Dr. Frank Yates, a psychologist at the University of Michigan. In these experiments, for example, two bookbags would be filled with the same number of poker chips; in one bag, two-thirds of the chips would be red and the rest white, with the opposite proportion in the other bag. A sample of chips was drawn from each bag, and the  task would be to determine, based on the samples drawn, whether a bag was more likely to have mostly red chips or white chips.
        If 5 chips were pulled from one bag and 4 were red, while 30 chips were taken out of the other and 20 were red, most people would say that the first bag was more likely to have mostly red chips because 80 percent of the 5 chips were red -- even though the larger sample size meant that the results for the second  bag would be more reliable.
        Dr. Barbara Tversky, Amos Tversky's wife and colleague in the Stanford psychology department, said the researchers showed that people tended to see patterns and make connections that were not really there and to base decisions on that.
        People were given this scenario: Suppose you pay $10 for a theater ticket but you lose the ticket on the way in -- will you return to the ticket window and buy another ticket? Or, suppose you arrive at the ticket window to buy your $10  ticket but find that you've lost $10 from your wallet. You still have enough money to buy the ticket -- do you go ahead? People would generally refuse to buy a second ticket, but, in the second set of circumstances, would tend to see the  loss of the money and the purchase of the ticket as unrelated, so they would buy the ticket. In both cases, of course, the net outcome would be the same.
        Dr. Tversky got a lot of attention in 1988 when he released a study during the basketball playoffs showing that contrary to popular belief, a basketball player who had just made a shot was no more likely, and even a little less likely, to make the next one. There is no "hot hand" in basketball, he showed by analyzing every shot taken by the Philadelphia 76ers in a year and a half.
        One part of Dr. Tversky's work with particular application to economics and policy making looked at how much importance people place on risks and benefits.  If people were asked to choose between a public health program that might save 600 lives or might lose them all and a program that would be guaranteed to save  400 of the 600 lives, they would choose the second program. But if the choice was framed as between a program with a 50 percent chance of saving 600 lives against one that would definitely lose 200 lives while saving 400, the tendency  was to choose the first program.
        Dr. Tversky was not averse to taking personal risks himself, Dr. Kahneman said. Dr. Tversky was born on March 16, 1937, in Haifa in what was then the British protectorate of Palestine. He fought in three Middle East wars, in 1956, 1967 and 1973, winning Israel's highest honor for bravery in a 1956 border skirmish.
        Dr. Kahneman said Dr. Tversky rescued a soldier who had gone forward with an  explosive charge to blow up some barbed wire and frozen, lying down on top of the explosive after lighting the fuse. He said Dr. Tversky reached the man and threw him to safety but was wounded.
        Dr. Tversky got his bachelor's degree from Hebrew University in 1961 and his  doctorate from the University of Michigan in 1965. He won many awards, including a MacArthur Foundation fellowship in 1984.
        In addition to his wife, he is survived by two sons, Oren, of San Francisco,  and Tal, of Stanford; a daughter, Dona, of Stanford, and a sister, Ruth Ariel, of Jerusalem.
      